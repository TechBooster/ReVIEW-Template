= 目的から考えよう
== AIは「手段」であり「目的」ではない
@<kw>{「目的から考える」}ことの大切さは、AIアプリ開発以外においても共通だと思います。
しかし、データを活用するAIアプリは一般的なWebアプリよりも、最初の目的設定が特に重要です。
なぜかと言うと、AIアプリ開発は、そのモデル構築に必要なデータを集めるところから作業が始まるからです。

データを集め、分析する段階から@<kw>{「実現したいこと（目的）があって、その実現手段として機械学習（技術）が存在する」}
という因果を忘れてはいけません。目的がなければ、どんなAIアプリ開発も必ず迷子になります。

夢を感じる最新技術はすぐにでも使ってみたいものです。しかし、それが課題を解決するための最適な技術なのかをしっかりと検討する必要があります。

また、AIは基本的に@<kw>{開発にも運用にもコストがかかります。}
機械学習を用いてデータ分析するためには大量なデータが必要であり、そのために、データを保管できる十分なデータベースが必要だからです。
さらに、構築したモデルの精度は最初から良い数値が出るのは稀です。
つまり、モデル構築に使用したアルゴリズムは、継続的に改善しつづける必要があるということです。

だからこそ、開発中に手戻りが起こらないように、データ分析の作業が短縮できるように、
目的に対して一貫性のある無駄のない設計をおこなう必要があるのです。

== 鍵を握るのは目的(変数)に必要なデータセットである
AIアプリ開発で必要なのは、何よりもまず@<kw>{目的(変数)に必要なデータセット}です。
日本の大企業がどれだけビッグデータを持っていても、データ活用が上手く進まないのはいくつかの理由があります。
その理由の1つは、蓄積されたデータが目的のために集められたデータではないため有効活用できないからです。

@<kw>{ただデータがあるだけでは、あなたの作りたいAIアプリを開発ことはできません。}これは紛れもない事実です。

== AI化までのステップ
AIを作るためには1つずつステップを踏んでいく必要があります。AI開発に王道なしです。
私はデータサイエンティストとして、クライアントがどのステップの段階にいるのかを見極めることを大切にしています。
私は図のようなピラミッド構造でAIプロジェクトを進めています。

== 目的設定
どんなAIを作りたいのか？つまり、どんなモデルを構築するのかを決めます。
目的は複数あることが多いので、@<kw>{1つの目的に、1つのモデルに整理し、1モデルごとに仮説を設定}します。
一般に、目的をモデルに落とし込む作業は機械学習の知識がなければ難しいでしょう。
ですから、このステップはデータサイエンティストに求められている大切な役割だと考えています。

=== 目的をモデルに落とし込んでみよう
目的をモデルに落とし込む方法は簡単です。
目的をどうするかを4つの選択肢から選んで整理するだけです。

4つの選択肢は
 1. 回帰：データを元に目的を説明する
 2. 分類：データを元に目的をAとBに分ける
 3. 推定：データを元に目的に与えている影響が何かを知る
 4. 予測：新しいデータから目的に関する未来の結果を得る
 です。

例えば、「私の理想の結婚相手と出逢うこと」が目的だとします。
このとき大切なことは「私の理想の結婚相手を@<kw>{どのように判断}したいのか」を1つに絞ってみることです。
「私の理想の結婚相手を@<kw>{予測}するモデル」「私の理想の結婚相手を@<kw>{分類}するモデル」は似て非なるモデルです。
分析のアプローチ方法が異なるのです。

図のようなシートで目的をモデルに変換してみましょう。
何となく実現したい目的が、具体的になってきた気がしませんか？

【最速デプロイのための目的整理シート】

=== 仮説を立て、データを当てはめてみよう
仮説とは、何らかの現象や法則性を説明する判断内容・条件のことを指します。
これも具体的に考えてみましょう。

あなたが結婚相手に求める条件は何でしょうか。2つ以上条件を考えてみてください。

 （考えてから読み進めてください）

 外見？収入？性格？いろいろあるでしょう。
 きっとみなさんは2つ以上簡単に条件をあげることができたのではないでしょうか。
 私はこれが目的に対して仮説を立てる力の根源だと思っています。

 あとはこれを少しだけ客観的に想像してみるだけです。
 「理想の結婚相手には年収1,000万以上が条件である私」は、
 メジャーなのかマジョリティなのかを想像してみましょう。

仮説は自分の価値観や体験を、みんなはどうなのだろうか？と想像して
少しだけ一般化して整理したものだと考えています。
あとはこの条件を知るためには、どのようなデータが必要なのかを図のシートで整理してみましょう。

【最速デプロイのための仮説のデータ化シート】

ここまでで、目的に対して必要なデータは何なのか？を整理することができました。
どうでしょう？あなたが作りたいモデルを作るために十分なデータは揃っていましたか？

難しく考えてしまうと、目的に必要なデータが何なのかわからなくなってしまいます。
@<kw>{目的に対して仮説を立てることができたらなら、あなたはもう立派なデータサイエンティスト}です。

特にAI化というのは、@<kw>{今まで人がやっていた判断基準を数値化・分類化する}ことが大きなテーマです。
その属人的な業務がいくつの要素で構成されており、それぞれの要素は目的に対してどのくらい影響しているか？
という仮説を立てて進めていきます。

理想の結婚相手の条件を挙げることができるあなたは、もうすでにこれができるのです。
このような感じで、AI化までのステップを理解していきましょう。

== データ収集基盤の構築
目的と仮説が明確になると、目的を実現するためのデータが不足しているかどうかを把握することができます。
必要なデータが不足している場合は、インターネット上に公開されているデータを活用したり、あるいはデータ収集基盤を構築します。

もちろん企業の場合は、既存データを活用して取り組もうとするケースが多いでしょう。
しかし、私は思い切って必要なデータを確実に蓄積できる@<kw>{データ収集基盤}を作ることをおすすめします。

理由は2つあります。まず、データ収集するタイミングを考えることは、属人的な業務のノウハウがどこに隠れているのかを深く理解することに繋がるからです。
つぎに、既存データを目的に使えるようにデータを整形する作業は想像以上に時間がかかって効率が悪いからです。

データ収集方法を考える作業は@<kw>{データとビジネスの距離感を近づけるとても大切なプロセス}です。
既存データのテーブル定義書だけを見ていても、実現したい目的に対しての本当の課題は理解することは難しいです。
逆に、データ収集方法を考えずに、ビジネスのお話だけを語っていてもAI開発は何も進まないのです。

== 数え上げ（count）／集計
いよいよデータが集まってきたらやるべきことは、@<kw>{分析ではなく集計}です。
このとき大切なことは、@<kw>{データラベル, 列名・カラム名}の意味を把握することと、indexに格納される値の種類と意味をしっかりと理解することです。
当たり前ですが、「◯◯日から◯◯日の間に何がいくつあるのか」といった「数えて、集める」という基本を徹底できずに有効なAIを作れるとは思いません。

一般的には、モデリング前に行う基礎分析は、@<kw>{探索的分析}を指します。
探索的分析はモデリングの精度を上げるためには非常に有効な分析プロセスです。
しかし、数字に対する肌感覚を掴むため、まずはこの基本的な集計作業をおこなうことを徹底するべきです。

また、これだけでも十分にデータによる意思決定（判断）ができます。
ですから、本書では無料だから個人でも使える「Googleデータポータル」というBIツールでの
ダッシュボード作成方法も付録で紹介しています。　

== 中間テーブル作成
中間テーブルは関連テーブルとも呼ばれ、多対多のデータの関係を表すテーブルを意味しています。
データベースを設計したことがない人にとっては専門的で難しいと思うので、詳しい説明は割愛します。

ざっくり言えば、@<kw>{分析やモデリングで必要な列と行だけを抽出したテーブル}だと理解していただければ十分です。
最初のステップで取り組んだ目的設定と仮説が明確であれば、中間テーブルを作ることは簡単です。
目的設定の段階で中間テーブルの列名（収集したいデータの項目）に目星がついているはずだからです。
私はここが@<kw>{データ分析を最短でデプロイするキーポイント}だと考えています。

大企業が保有しているデータを活用してAIを作るときは、どこにどんなデータが存在しているのかを把握するにも一苦労です。
特に、それぞれのデータテーブルがそれぞれの目的をもって存在しているため、中間テーブルを作ること自体が困難な場合も少なくありません。

実際、データ分析に至るまでのステップに時間がかかります。
ですから、今回のAIアプリでは、このステップから始められるようにオープンデータを活用して
サンプルアプリを開発していきます。

== データ分析
@<comment>{ここの文章はあとで変更する}
みなさんがイメージしている機械学習を使ったデータ分析をおこないます。
このステップがデータサイエンティストとしての醍醐味なような気もしますが、
最も機械による自動化が進んでいると思っています。
また、参考書籍やインターネットに情報も豊富なので、
本書でも詳しく説明する予定はありません。

== モデリング（モデル構築）
@<comment>{ここの文章はあとで変更する}
AIのアルゴリズムの元となるモデル構築します。
この部分も機械が最も精度の高いアルゴリズムを選定してくれるので、あまり時間をかけずに進めていきます。

もちろん、モデル選定後にそのモデル自体の予測／分類精度を向上させることは大切です。この精度が低ければ、ただの人工無脳になってしまいますからね（笑）
一方で、デプロイ後にも改善できることも理解して欲しいです。目の前にカタチになったプロダクトがあったほうが進捗を感じます。

今回も精度改善の優先順位は少し下げて、次のステップへ進んでいきます。

== AI化
使用した技術と実現したい目的によって、AI化の定義は変わります。
今回は予測モデルをAPI化することによって、既存のアプリケーション内のシステムに組み込みます。
予測モデルを組み込んだアプリケーションをAI化されたAIアプリと定義します。

本書では、予測モデルをシステムに組み込める形式でエクスポートします。
それを使ってAPIを作成していきましょう。

今回は、最短でここまで走りきることが目標です。
モデルの精度向上はそのあとに取り組むプロセスにしています。
おそらく、そのほうがAIアプリ開発を途中で諦めたりすることがなくなると思ったからです。

組み込むことができれば、AIアプリの完成です。
データ分析をデプロイできました。
