= 目的から考えよう
//lead{
実際にAIアプリを作り始める前に、AIアプリを開発するに当たって事前に考えるべきことをご紹介します。
//}
== 機械学習プロジェクトの失敗あるある
 失敗する要因として、@<kw>{手段が目的になってしまって失敗する}ケースがとても多いです。

 「とにかくAI化してみたい！」という気持ちはとてもわかります。最新の技術はすぐにでも使ってみたいものです。しかし、それが課題を解決するための適切な技術なのかを検討する必要があります。
 なぜなら、機械学習を用いてデータを活用するためにはデータを保管する大量のデータベースが必要です。モデルを継続的に改善しつづける必要もあります。@<kw>{開発にも運用にもコストがかかる}のです。

 AI開発で必要なのは、何よりもまず@<kw>{目的(変数)に必要なデータセット}です。
 日本の大企業がどれだけビッグデータを持っていても、データ活用が上手く進まないのはいくつかの理由があります。その理由の1つは、「目的のために集められたデータセットではないため有効活用できないのです。

 わたし個人の意見ですが、昔のデータが使えないのならいち早く@<kw>{「データ収集基盤」を作る}ことをオススメしています。データクレンジングがデータの値や取得の背景を理解するにも時間がかかります。
 しかし、目的に対して効果が大きいデータは直近に取得したデータです。だからこそ、目的に必要なデータを適切な形で収集できる基盤を作るアプローチのほうが最短で目的を達成できると考えています。

 ここでは、@<kw>{①AIアプリは開発・運用コストが高いこと②目的に合ったデータセットが必要であること}の2点を理解し、そもそも機械学習は目的変数に必要な説明変数がなければ適切に活用できないことを改めて認識していただければと思います。@<kw>{ただデータがあるだけでは、あなたの作りたいAIを作ることはできません。}

== 目的に対して仮説を立てる
 だからこそ、データサイエンティストの役割は@<kw>{複数ある目的を1モデル1目的に整理し、それぞれ仮説を設定する}ことだと考えています。1つのモデルで複数の目的を達成できると過信しないことが大切です。

 例えば、「私の理想の結婚相を予測する」ことを目的とした予測モデルを作ってみるとしましょう。あなたが結婚相手に求める条件は何でしょうか。2つ以上条件を考えてみてください。

 （考えてから読み進めてください）外見？収入？性格？いろいろあるでしょう。きっとみなさんは2つ以上簡単に条件をあげることができたのではないでしょうか。私はこれが目的に対して仮説を立てる力だと信じています。

 難しく考えてしまうと、目的に必要なデータが何なのかわからなくなってしまいがちです。でもこれで十分ではありませんか？@<kw>{目的に対して仮説をたてることができたらなら、あなたはもう立派なデータサイエンティスト}です。この感覚を意識して、AI化までのステップを理解していきましょう。

== AI化までのステップを知ろう
いろいろな書籍で、AIプロジェクトの進め方のフローが紹介されています。私は図のようなピラミッド構造でAIプロジェクトを進めています。
//image[AiProject_step][AIステップピラミッド][scale=0.9]
=== 目的設計
最も重要なプロセスだと信じています。何のためにモデルを構築するのかを明確にします。
ここでは目的に対して、必要なデータは何なのか？まで整理することが大切です。

特にAI化というのは、人の業務の型化することが大きなテーマになります。その属人的な業務がいくつの要素で構成されており、それぞれの要素は目的に対してどのくらい影響しているか？の仮説を立てていきます。
大丈夫です。理想の結婚相手の条件を挙げることができるあなたは、もうすでにこれができるのです。

=== データ収集基盤の構築
目的を明確にすると、既存のデータでは不足していることが少なくありません。必要なデータが不足している場合は、データ収集基盤を構築します。

私は既存のデータでできることをやろうとするよりも、一層、精緻なデータ収集スキームを設計することをおすすめしています。
理由は、データ収集するタイミングを考えることは、属人的な業務のノウハウがどこに隠れているのかを深く理解することができるからです。

データ収集基盤構築は、アンケートでもいいと思います。この作業はデータとビジネスの距離感を近づけるとても大切なプロセスです。
テーブル定義書岳を見ていてもビジネスのことや本当の課題は理解できないし、データを見ずにビジネス論を語っていても何も進まないのです。

=== 集計／count
データが集まってきたらやるべきことは、分析ではなく@<kw>{集計}です。このとき大切なことは、改めてデータテーブルの列名（column）の意味を把握することと、indexに格納される値の種類と意味をしっかりと理解することです。

この基本的な集計作業をしっかりと行えば、目的設計で行った仮説が合っていたのか、外れていたのかをおおよそ当てることができます。分析しなくても、仮説の打率はおおよそ予測できます。だってもともと人がやっていたことを統計と機械の力を借りて型（モデル）にするだけですからね。
=== 中間テーブル作成
中間テーブルとは、そのデータを機械学習アルゴリズムで計算すれば、モデルが作れる整形済データセットのことを指します。目的が明確であれば、中間テーブルを作ることは簡単です。

目的設計の段階で中間テーブルの列名（収集したいデータの項目）は明確になっているはずです。私はここが@<kw>{データ分析を最短でデプロイするキーとなるポイント}だと信じています。

=== 機械学習を活用したデータ分析
みなさんがイメージしているデータ分析です。データ量を確認し、欠損の有無や欠損値を補完します。
その後、交差検証（要確認）などを行い、中間テーブルをより洗練されたものに進化させていきます。

個人的には、ここがデータサイエンティストとしての醍醐味なような気もしますが、この部分は最も機械による自動化が進んでいると思っています。
ですので本書でも詳しく説明する予定はありません。

大事なのは、ヒトであるわたしたちでしかできない目的設計とそれを具体化させた中間テーブルの設計です。
アカデミックである場合は別ですが、ここに時間をかけないことがデプロイまでの時間を短縮化させるポイントです。

=== モデル構築
実際にAIのアルゴリズムの元となるアルゴリズムを構築します。
この部分も機械が最も精度の高いアルゴリズムを選定してくれるので、あまり時間をかけずに進めていきます。

もちろん、モデル選定後にそのモデル自体の予測／分類精度を向上させることは大切です。この精度が低ければ、ただの人工無脳になってしまいますからね（笑）
一方で、デプロイ後にも改善できることも理解して欲しいです。目の前にカタチになったプロダクトがあったほうが進捗を感じます。

今回も精度改善の優先順位は少し下げて、次のステップへ進んでいきます。

=== システム組み込み（AI化）
AIアプリの定義はいろいろあると思いますが、今回はモデルをAPI化することによって既存のアプリケーション内のシステムに組み込むこととします。

モデルをシステムに組み込めるカタチで吐き出し、APIを作成していきましょう。ここまで走りきってからモデル改善にこだわったほうが、おそらく息が長く続きます。
ここまで進めばAIアプリの完成です。データ分析をデプロイすることができました。

== 新米データサイエンティストに必要な要素


===[column]
@<kw>{私が出会った企業内のAIプロジェクトがうまくいかない理由}
//image[shippai_AiProject][実際の企業内データ構造][scale=0.9]


===[/column]
